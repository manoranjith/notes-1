# this vagrant files setups kubernetes 1.14 cluster

# in addition to master, how many worker nodes needed in cluster
workers=3

# the master will have ip <subnet>.10
# worker nodes will have ip <subnet>.11, <subnet>.12, ...
subnet="172.28.128"

# https://kubernetes.io/docs/setup/cri/#docker
$install_docker = <<'EOF_SCRIPT'
set -ex

# fix for: dpkg-reconfigure: unable to re-open stdin: No file or directory
export DEBIAN_FRONTEND=noninteractive

# Install packages to allow apt to use a repository over HTTPS
apt-get update
apt-get install -y apt-transport-https ca-certificates curl software-properties-common

# Add Dockerâ€™s official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -

# Add Docker apt repository
add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/$(. /etc/os-release; echo "$ID") \
   $(lsb_release -cs) \
   stable"

# Install Docker CE
apt-get update && apt-get install -y docker-ce=$(apt-cache madison docker-ce | grep 18.06.2 | head -1 | awk '{print $3}')

# Setup daemon.
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
mkdir -p /etc/systemd/system/docker.service.d

# Restart docker
systemctl daemon-reload
systemctl restart docker

# add vagrant user to docker group. this is reqd to access docker cli
usermod -a -G docker vagrant
EOF_SCRIPT

# https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl
$install_kube_commands = <<'EOF_SCRIPT'
set -ex

# fix for: dpkg-reconfigure: unable to re-open stdin: No file or directory
export DEBIAN_FRONTEND=noninteractive

apt-get update && apt-get install -y apt-transport-https
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
version=1.14
apt-get install -y kubelet=$(apt-cache madison kubelet | grep $version | head -1 | awk '{print $3}')
apt-get install -y kubeadm=$(apt-cache madison kubeadm | grep $version | head -1 | awk '{print $3}')
apt-get install -y kubectl=$(apt-cache madison kubectl | grep $version | head -1 | awk '{print $3}')

# use non-NAT interface ip-address
ipaddr=`ifconfig enp0s8 | grep 'inet addr' | cut -d: -f2 | awk '{print $1}'`
if [ -f "/etc/default/kubelet" ]; then
    sed -i "s/^KUBELET_EXTRA_ARGS=/KUBELET_EXTRA_ARGS=--node-ip=$ipaddr/" /etc/default/kubelet
else
    echo "KUBELET_EXTRA_ARGS=--node-ip=$ipaddr" > /etc/default/kubelet
fi
EOF_SCRIPT

# https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#24-initializing-your-master
$create_cluster = <<'EOF_SCRIPT'
set -ex
ipaddr=`ifconfig enp0s8 | grep 'inet addr' | cut -d: -f2 | awk '{print $1}'`
kubeadm init --apiserver-advertise-address=$ipaddr --pod-network-cidr=10.244.0.0/16
kubeadm token create --print-join-command > /vagrant/kubeadm-join.sh
EOF_SCRIPT

# https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network
$install_pod_network = <<'EOF_SCRIPT'
set -ex
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# note: we have to add --iface=enp0s8 to get flannel working in vagrant
# see https://coreos.com/flannel/docs/latest/running.html#running-on-vagrant
curl -O -s https://raw.githubusercontent.com/coreos/flannel/62e44c867a2846fefb68bd5f178daf4da3095ccb/Documentation/kube-flannel.yml
sed -i 's/- --kube-subnet-mgr/- --kube-subnet-mgr\n        - --iface=enp0s8/g' kube-flannel.yml
kubectl apply -f kube-flannel.yml

arch=`kubectl get node master -o 'jsonpath={.metadata.labels.beta\.kubernetes\.io/arch}'`
for i in {1..100}; do
  echo iteration $i...
  sleep 5
  if kubectl -n kube-system get daemonset kube-flannel-ds-${arch} -o 'jsonpath={.status.numberAvailable}' | grep 1; then
    break
  fi
done
kubectl -n kube-system get daemonset kube-flannel-ds-${arch} -o 'jsonpath={.status.numberAvailable}' | grep 1
EOF_SCRIPT

$install_nfs_server = <<'EOF_SCRIPT'
set -ex
export DEBIAN_FRONTEND=noninteractive
apt install -y nfs-kernel-server
mkdir /kubedata
chmod 777 /kubedata
echo "/kubedata *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)" >> /etc/exports
exportfs -rav

cp /etc/kubernetes/admin.conf /vagrant
EOF_SCRIPT

$install_nfs_client = <<'EOF_SCRIPT'
set -ex
export DEBIAN_FRONTEND=noninteractive
apt install -y nfs-common
mkdir -p /home/vagrant/.kube
cp /vagrant/admin.conf /home/vagrant/.kube/config
sudo chown -R vagrant:vagrant /home/vagrant/.kube
EOF_SCRIPT

$install_nfs_provisioner = <<'EOF_SCRIPT'
set -ex
nfs_server_ip=$1
curl -sO https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/rbac.yaml
kubectl create -f rbac.yaml
rm rbac.yaml

curl -sO https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/class.yaml
kubectl create -f class.yaml
rm class.yaml

curl -sO https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/deployment.yaml
sed -i s/10.10.10.60/$nfs_server_ip/g deployment.yaml
sed -i s:/ifs/kubernetes:/kubedata:g deployment.yaml
sed -i '0,/---$/d' deployment.yaml # remove service-account duplicate defintion
kubectl create -f deployment.yaml
rm deployment.yaml

for i in {1..100}; do
  echo iteration $i...
  sleep 5
  if kubectl get deployment nfs-client-provisioner -o 'jsonpath={.status.availableReplicas}' | grep 1; then
    break
  fi
done
EOF_SCRIPT

Vagrant.configure("2") do |config|
  config.vm.provider "virtualbox" do |vb|
    vb.memory = 2048
    vb.cpus = 2
  end
  
  config.vm.box = "ubuntu/xenial64"
  config.vm.provision "install_docker", type: "shell", inline: $install_docker
  config.vm.provision "install_kube_commands", type: "shell", inline: $install_kube_commands

  config.vm.define "master", primary: true do |master|
    master.vm.hostname = "master"
	  master.vm.network "private_network", ip: "#{subnet}.10"
    master.vm.provision "create_cluster", type: "shell", inline: $create_cluster
    master.vm.provision "install_pod_network", type: "shell", inline: $install_pod_network, privileged: false
    master.vm.provision "install_nfs_server", type: "shell", inline: $install_nfs_server
  end

  (1..workers).each do |i|
    config.vm.define "worker#{i}" do |node|
      node.vm.hostname = "worker#{i}"
      node.vm.network "private_network", ip: "#{subnet}.#{i+10}"
      node.vm.provision "join_cluster", type: "shell", path: "kubeadm-join.sh"
      node.vm.provision "install_nfs_client", type: "shell", inline: $install_nfs_client
      if i == workers
        node.vm.provision "install_nfs_provisioner", type: "shell", inline: $install_nfs_provisioner, args: ["#{subnet}.10"], privileged: false
      end
    end
  end
end
